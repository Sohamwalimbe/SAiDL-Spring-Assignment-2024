# -*- coding: utf-8 -*-
"""GNN_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16DkPB21ULSQLiWT3OjMAPnB9oFUDgD1C
"""

!pip install torch_geometric

import torch
import torch.nn as nn
import torch.nn.functional as F
#from torch_geometric.nn import GATConv
from torch_geometric.datasets import PPI
from torch_geometric.data import DataLoader
from sklearn.model_selection import train_test_split
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import softmax # asked karan if i could use this, he said yes :))

# GAT Layer implementation using Message Passing base class
class GATLayer(MessagePassing):
  def __init__(self,f_in,f_out,neg):
    super().__init__(aggr="add")

    self.f_in = f_in
    self.f_out = f_out
    self.neg = neg
    self.Lrelu = nn.LeakyReLU(self.neg)

    self.weight = nn.Linear(self.f_in,self.f_out)
    self.attention = nn.Linear(2*self.f_out,1)
    self.init_weights()

  def init_weights(self):
    stdv = 1.0 / ((self.f_out + self.f_in) ** 0.5)
    for weight in self.parameters():
        weight.data.uniform_(-stdv, stdv)

  def forward(self,x,edge_index):
    wh = self.weight(x)

    res = self.propagate(edge_index,x=wh)
    return res

  def message(self, edge_index_i, x_i, x_j, size_i):
    x_cat = torch.cat([x_i, x_j], dim=-1)
    eij = self.attention(x_cat)
    alpha = softmax(eij, edge_index_i, num_nodes=size_i)
    res = alpha * x_j
    return res

# The complete GNN model
class GAT(nn.Module):
  def __init__(self,in_channels,hidden_channels,out_channels,num_layers,neg=0.2):
    super().__init__()
    self.num_layers = num_layers
    self.layers = nn.ModuleList()
    self.layers.append(GATLayer(in_channels,hidden_channels,neg))
    for i in range(num_layers-2):
      self.layers.append(GATLayer(hidden_channels,hidden_channels,neg))
    self.layers.append(GATLayer(hidden_channels,out_channels,neg))

  def forward(self,x,edge_index):
    for i in range(self.num_layers):
      x = self.layers[i](x,edge_index)
    return x

# Used initially for checking the pipeline
# class GAT(torch.nn.Module):
#     def __init__(self, in_channels, hidden_channels, out_channels, num_layers, heads):
#         super(GAT, self).__init__()
#         self.convs = nn.ModuleList()
#         self.convs.append(GATConv(in_channels, hidden_channels, heads=heads))
#         for _ in range(num_layers - 2):
#             self.convs.append(GATConv(hidden_channels * heads, hidden_channels, heads=heads))
#         self.convs.append(GATConv(hidden_channels * heads, out_channels, heads=1))

#     def forward(self, x, edge_index):
#         for conv in self.convs[:-1]:
#             x = F.relu(conv(x, edge_index))
#             x = F.dropout(x, p=0.6, training=self.training)
#         return self.convs[-1](x, edge_index)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

dataset = PPI(root='/tmp/PPI')
#dataset = dataset[:1000]
train_dataset, test_dataset = train_test_split(dataset, test_size=0.2)
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
print(dataset.num_features)

model = GAT(dataset.num_features, hidden_channels=64, out_channels=dataset.num_classes,
            num_layers=3).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.BCEWithLogitsLoss()

model.train()
num_epochs = 100
for epoch in range(num_epochs):
    total_loss = 0
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data.x, data.edge_index)
        loss = criterion(out, data.y.view(-1, dataset.num_classes))
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs
    total_loss /= len(train_loader.dataset)
    print('Epoch {}, Loss {:.4f}'.format(epoch, total_loss))

model.eval()
correct = 0
total = 0
for data in test_loader:
    data = data.to(device)
    with torch.no_grad():
        out = model(data.x, data.edge_index)
        pred = (out > 0).float()
    correct += (pred == data.y).sum().item()
    total += data.y.size(0)

accuracy = correct / total
print('Test Accuracy: {:.4f}'.format(accuracy))